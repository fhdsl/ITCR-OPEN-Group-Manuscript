
@article{wratten_reproducible_2021,
	title = {Reproducible, scalable, and shareable analysis pipelines with bioinformatics workflow managers},
	volume = {18},
	issn = {1548-7091, 1548-7105},
	url = {https://www.nature.com/articles/s41592-021-01254-9},
	doi = {10.1038/s41592-021-01254-9},
	language = {en},
	number = {10},
	urldate = {2022-08-01},
	journal = {Nature Methods},
	author = {Wratten, Laura and Wilm, Andreas and Göke, Jonathan},
	month = oct,
	year = {2021},
	pages = {1161--1168},
	file = {Wratten et al. - 2021 - Reproducible, scalable, and shareable analysis pip.pdf:/Users/carriewright/Zotero/storage/AXVAIJ7G/Wratten et al. - 2021 - Reproducible, scalable, and shareable analysis pip.pdf:application/pdf},
}

@article{dozmorov_github_2018,
	title = {{GitHub} {Statistics} as a {Measure} of the {Impact} of {Open}-{Source} {Bioinformatics} {Software}},
	volume = {6},
	issn = {2296-4185},
	url = {https://www.frontiersin.org/articles/10.3389/fbioe.2018.00198},
	abstract = {Modern research is increasingly data-driven and reliant on bioinformatics software. Publication is a common way of introducing new software, but not all bioinformatics tools get published. Giving there are competing tools, it is important not merely to find the appropriate software, but have a metric for judging its usefulness. Journal's impact factor has been shown to be a poor predictor of software popularity; consequently, focusing on publications in high-impact journals limits user's choices in finding useful bioinformatics tools. Free and open source software repositories on popular code sharing platforms such as GitHub provide another venue to follow the latest bioinformatics trends. The open source component of GitHub allows users to bookmark and copy repositories that are most useful to them. This Perspective aims to demonstrate the utility of GitHub “stars,” “watchers,” and “forks” (GitHub statistics) as a measure of software impact. We compiled lists of impactful bioinformatics software and analyzed commonly used impact metrics and GitHub statistics of 50 genomics-oriented bioinformatics tools. We present examples of community-selected best bioinformatics resources and show that GitHub statistics are distinct from the journal's impact factor (JIF), citation counts, and alternative metrics (Altmetrics, CiteScore) in capturing the level of community attention. We suggest the use of GitHub statistics as an unbiased measure of the usability of bioinformatics software complementing the traditional impact metrics.},
	urldate = {2022-08-01},
	journal = {Frontiers in Bioengineering and Biotechnology},
	author = {Dozmorov, Mikhail G.},
	year = {2018},
	file = {Full Text PDF:/Users/carriewright/Zotero/storage/9IIHYJHK/Dozmorov - 2018 - GitHub Statistics as a Measure of the Impact of Op.pdf:application/pdf},
}

@article{network_diversifying_2022,
	title = {Diversifying the genomic data science research community},
	issn = {1088-9051, 1549-5469},
	url = {https://genome.cshlp.org/content/early/2022/07/18/gr.276496.121},
	doi = {10.1101/gr.276496.121},
	abstract = {An international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms},
	language = {en},
	urldate = {2022-08-01},
	journal = {Genome Research},
	author = {Network, The Genomic Data Science Community and Alcazar, Rosa and Alvarez, Maria and Arnold, Rachel and Ayalew, Mentewab and Best, Lyle G. and Campbell, Michael C. and Chowdhury, Kamal and Cox, Katherine E. L. and Daulton, Christina and Deng, Youping and Easter, Carla and Fuller, Karla and Hakim, Shazia Tabassum and Hoffman, Ava M. and Kucher, Natalie and Lee, Andrew and Lee, Joslynn and Leek, Jeffrey T. and Meller, Robert and Méndez, Loyda B. and Méndez-González, Miguel P. and Mosher, Stephen and Nishiguchi, Michele and Pratap, Siddharth and Rolle, Tiffany and Roy, Sourav and Saidi, Rachel and Schatz, Michael C. and Sen, Shurjo K. and Sniezek, James and Martinez, Edu Suarez and Tan, Frederick J. and Vessio, Jennifer and Watson, Karriem and Westbroek, Wendy and Wilcox, Joseph and Wright, Carrie and Xie, Xianfa},
	month = jul,
	year = {2022},
	note = {Company: Cold Spring Harbor Laboratory Press
Distributor: Cold Spring Harbor Laboratory Press
Institution: Cold Spring Harbor Laboratory Press
Label: Cold Spring Harbor Laboratory Press
Publisher: Cold Spring Harbor Lab},
	file = {Full Text PDF:/Users/carriewright/Zotero/storage/Z2VDT6MI/Network et al. - 2022 - Diversifying the genomic data science research com.pdf:application/pdf;Snapshot:/Users/carriewright/Zotero/storage/XKKXZP7M/gr.276496.121.html:text/html},
}

@inproceedings{brun_software_2018,
	address = {Lake Buena Vista FL USA},
	title = {Software fairness},
	isbn = {978-1-4503-5573-5},
	url = {https://dl.acm.org/doi/10.1145/3236024.3264838},
	doi = {10.1145/3236024.3264838},
	abstract = {A goal of software engineering research is advancing software quality and the success of the software engineering process. However, while recent studies have demonstrated a new kind of defect in software related to its ability to operate in fair and unbiased manner, software engineering has not yet wholeheartedly tackled these new kinds of defects, thus leaving software vulnerable. This paper outlines a vision for how software engineering research can help reduce fairness defects and represents a call to action by the software engineering research community to reify that vision. Modern software is riddled with examples of biased behavior, from automated translation injecting gender stereotypes, to vision systems failing to see faces of certain races, to the US criminal justice system relying on biased computational assessments of crime recidivism. While systems may learn bias from biased data, bias can also emerge from ambiguous or incomplete requirement specification, poor design, implementation bugs, and unintended component interactions. We argue that software fairness is analogous to software quality, and that numerous software engineering challenges in the areas of requirements, specification, design, testing, and verification need to be tackled to solve this problem.},
	language = {en},
	urldate = {2022-09-02},
	booktitle = {Proceedings of the 2018 26th {ACM} {Joint} {Meeting} on {European} {Software} {Engineering} {Conference} and {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Brun, Yuriy and Meliou, Alexandra},
	month = oct,
	year = {2018},
	pages = {754--759},
	file = {Brun and Meliou - 2018 - Software fairness.pdf:/Users/carriewright/Zotero/storage/G56KK2VD/Brun and Meliou - 2018 - Software fairness.pdf:application/pdf},
}

@article{weber_essential_2019,
	title = {Essential guidelines for computational method benchmarking},
	volume = {20},
	issn = {1474-760X},
	url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1738-8},
	doi = {10.1186/s13059-019-1738-8},
	language = {en},
	number = {1},
	urldate = {2022-09-09},
	journal = {Genome Biology},
	author = {Weber, Lukas M. and Saelens, Wouter and Cannoodt, Robrecht and Soneson, Charlotte and Hapfelmeier, Alexander and Gardner, Paul P. and Boulesteix, Anne-Laure and Saeys, Yvan and Robinson, Mark D.},
	month = dec,
	year = {2019},
	pages = {125},
	file = {Full Text:/Users/carriewright/Zotero/storage/WCXL5ATD/Weber et al. - 2019 - Essential guidelines for computational method benc.pdf:application/pdf},
}

@article{buchka_optimistic_2021,
	title = {On the optimistic performance evaluation of newly introduced bioinformatic methods},
	volume = {22},
	issn = {1474-760X},
	url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02365-4},
	doi = {10.1186/s13059-021-02365-4},
	abstract = {Abstract
            Most research articles presenting new data analysis methods claim that “the new method performs better than existing methods,” but the veracity of such statements is questionable. Our manuscript discusses and illustrates consequences of the optimistic bias occurring during the evaluation of novel data analysis methods, that is, all biases resulting from, for example, selection of datasets or competing methods, better ability to fix bugs in a preferred method, and selective reporting of method variants. We quantitatively investigate this bias using an example from epigenetic analysis: normalization methods for data generated by the Illumina HumanMethylation450K BeadChip microarray.},
	language = {en},
	number = {1},
	urldate = {2022-09-09},
	journal = {Genome Biology},
	author = {Buchka, Stefan and Hapfelmeier, Alexander and Gardner, Paul P. and Wilson, Rory and Boulesteix, Anne-Laure},
	month = dec,
	year = {2021},
	pages = {152},
	file = {Full Text:/Users/carriewright/Zotero/storage/KL5GE35V/Buchka et al. - 2021 - On the optimistic performance evaluation of newly .pdf:application/pdf},
}

@article{mangul_challenges_2019,
	title = {Challenges and recommendations to improve the installability and archival stability of omics computational tools},
	volume = {17},
	issn = {1545-7885},
	url = {https://dx.plos.org/10.1371/journal.pbio.3000333},
	doi = {10.1371/journal.pbio.3000333},
	language = {en},
	number = {6},
	urldate = {2022-09-09},
	journal = {PLOS Biology},
	author = {Mangul, Serghei and Mosqueiro, Thiago and Abdill, Richard J. and Duong, Dat and Mitchell, Keith and Sarwal, Varuni and Hill, Brian and Brito, Jaqueline and Littman, Russell Jared and Statz, Benjamin and Lam, Angela Ka-Mei and Dayama, Gargi and Grieneisen, Laura and Martin, Lana S. and Flint, Jonathan and Eskin, Eleazar and Blekhman, Ran},
	month = jun,
	year = {2019},
	pages = {e3000333},
	file = {Full Text:/Users/carriewright/Zotero/storage/YNSAFMZL/Mangul et al. - 2019 - Challenges and recommendations to improve the inst.pdf:application/pdf},
}

@article{gardner_sustained_2022,
	title = {Sustained software development, not number of citations or journal choice, is indicative of accurate bioinformatic software},
	volume = {23},
	issn = {1474-760X},
	url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02625-x},
	doi = {10.1186/s13059-022-02625-x},
	abstract = {Abstract
            
              Background
              Computational biology provides software tools for testing and making inferences about biological data. In the face of increasing volumes of data, heuristic methods that trade software speed for accuracy may be employed. We have studied these trade-offs using the results of a large number of independent software benchmarks, and evaluated whether external factors, including speed, author reputation, journal impact, recency and developer efforts, are indicative of accurate software.
            
            
              Results
              We find that software speed, author reputation, journal impact, number of citations and age are unreliable predictors of software accuracy. This is unfortunate because these are frequently cited reasons for selecting software tools. However, GitHub-derived statistics and high version numbers show that accurate bioinformatic software tools are generally the product of many improvements over time. We also find an excess of slow and inaccurate bioinformatic software tools, and this is consistent across many sub-disciplines. There are few tools that are middle-of-road in terms of accuracy and speed trade-offs.
            
            
              Conclusions
              Our findings indicate that accurate bioinformatic software is primarily the product of long-term commitments to software development. In addition, we hypothesise that bioinformatics software suffers from publication bias. Software that is intermediate in terms of both speed and accuracy may be difficult to publish—possibly due to author, editor and reviewer practises. This leaves an unfortunate hole in the literature, as ideal tools may fall into this gap. High accuracy tools are not always useful if they are slow, while high speed is not useful if the results are also inaccurate.},
	language = {en},
	number = {1},
	urldate = {2022-09-09},
	journal = {Genome Biology},
	author = {Gardner, Paul P. and Paterson, James M. and McGimpsey, Stephanie and Ashari-Ghomi, Fatemeh and Umu, Sinan U. and Pawlik, Aleksandra and Gavryushkin, Alex and Black, Michael A.},
	month = dec,
	year = {2022},
	pages = {56},
	file = {Full Text:/Users/carriewright/Zotero/storage/47PC6PKE/Gardner et al. - 2022 - Sustained software development, not number of cita.pdf:application/pdf},
}

@misc{loman_bioinformatics_2015,
	title = {Bioinformatics infrastructure and training survey},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://figshare.com/articles/dataset/Bioinformatics_infrastructure_and_training_summary/1572287/2},
	abstract = {We undertook a poll of bioinformaticians, marketed through Twitter, in order to understand more about the current issues with bioinformatics practice and training. Methods: Through using a public Google Form we asked questions relating to frustrations, working practices, limitations of working practices. We also assessed whether the survey participant was UK based and what level of self-declared skill they had. Users had the opportunity to read the other responses to the survey, and edit or delete their answers. Results: 272 responses were received in the period 6th October 2015 to 12 October 2015 (7 days). This fileset presents the form, the responses (in Excel and CSV format) and the summary responses. The results may be of use for those wishing to understand more about the current issues facing bioinformaticians and bioinformatics training. The results are distributed under the CC-BY license. We are grateful to all participants who took the time to fill out this survey.},
	urldate = {2022-09-09},
	publisher = {figshare},
	author = {Loman, Nicholas and Connor, Thomas},
	year = {2015},
	doi = {10.6084/M9.FIGSHARE.1572287.V2},
	note = {Artwork Size: 1026785 Bytes
Pages: 1026785 Bytes
Type: dataset},
	keywords = {60102 Bioinformatics, Computational Biology, FOS: Computer and information sciences},
}

@article{ison_biotoolsschema_2021,
	title = {{biotoolsSchema}: a formalized schema for bioinformatics software description},
	volume = {10},
	issn = {2047-217X},
	shorttitle = {{biotoolsSchema}},
	url = {https://academic.oup.com/gigascience/article/doi/10.1093/gigascience/giaa157/6121637},
	doi = {10.1093/gigascience/giaa157},
	abstract = {Background: Life scientists routinely face massive and heterogeneous data analysis tasks and must find and access the most suitable databases or software in a jungle of web-accessible resources. The diversity of information used to describe life-scientific digital resources presents an obstacle to their utilization. Although several standardization efforts are emerging, no information schema has been sufficiently detailed to enable uniform semantic and syntactic description—and cataloguing—of bioinformatics resources. Findings: Here we describe biotoolsSchema, a formalized information model that balances the needs of conciseness for rapid adoption against the provision of rich technical information and scientific context. biotoolsSchema results from a series of community-driven workshops and is deployed in the bio.tools registry, providing the scientific community with {\textgreater}17,000 machine-readable and human-understandable descriptions of software and other digital life-science resources. We compare our approach to related initiatives and provide alignments to foster interoperability and reusability. Conclusions: biotoolsSchema supports the formalized, rigorous, and consistent specification of the syntax and semantics of bioinformatics resources, and enables cataloguing efforts such as bio.tools that help scientists to find, comprehend, and compare resources. The use of biotoolsSchema in bio.tools promotes the FAIRness of research software, a key element of open and reproducible developments for data-intensive sciences.},
	language = {en},
	number = {1},
	urldate = {2022-09-09},
	journal = {GigaScience},
	author = {Ison, Jon and Ienasescu, Hans and Rydza, Emil and Chmura, Piotr and Rapacki, Kristoffer and Gaignard, Alban and Schwämmle, Veit and van Helden, Jacques and Kalaš, Matúš and Ménager, Hervé},
	month = jan,
	year = {2021},
	pages = {giaa157},
	file = {Ison et al. - 2021 - biotoolsSchema a formalized schema for bioinforma.pdf:/Users/carriewright/Zotero/storage/GJ87HCSE/Ison et al. - 2021 - biotoolsSchema a formalized schema for bioinforma.pdf:application/pdf},
}

@article{hummel_data_2021,
	title = {Data sovereignty: {A} review},
	volume = {8},
	issn = {2053-9517},
	shorttitle = {Data sovereignty},
	url = {https://doi.org/10.1177/2053951720982012},
	doi = {10.1177/2053951720982012},
	abstract = {New data-driven technologies yield benefits and potentials, but also confront different agents and stakeholders with challenges in retaining control over their data. Our goal in this study is to arrive at a clear picture of what is meant by data sovereignty in such problem settings. To this end, we review 341 publications and analyze the frequency of different notions such as data sovereignty, digital sovereignty, and cyber sovereignty. We go on to map agents they concern, in which context they appear, and which values they allude to. While our sample reveals a considerable degree of divergence and an occasional lack of clarity about intended meanings of data sovereignty, we propose a conceptual grid to systematize different dimensions and connotations. Each of them relates in some way to meaningful control, ownership, and other claims to data articulated by a variety of agents ranging from individuals to countries. Data sovereignty alludes to a nuanced mixture of normative concepts such as inclusive deliberation and recognition of the fundamental rights of data subjects.},
	language = {en},
	number = {1},
	urldate = {2022-09-26},
	journal = {Big Data \& Society},
	author = {Hummel, Patrik and Braun, Matthias and Tretter, Max and Dabrock, Peter},
	month = jan,
	year = {2021},
	note = {Publisher: SAGE Publications Ltd},
	pages = {2053951720982012},
	file = {SAGE PDF Full Text:/Users/carriewright/Zotero/storage/ARGBY6P4/Hummel et al. - 2021 - Data sovereignty A review.pdf:application/pdf},
}

@misc{zenodo,
	title = {Zenodo - {Research}. {Shared}.},
	url = {https://blog.zenodo.org/page/3/},
	abstract = {Zenodo is a free and open digital archive built by CERN and OpenAIRE, enabling researchers to share and preserve research output in any size, format and from all fields of research.},
	urldate = {2022-09-29},
	file = {Snapshot:/Users/carriewright/Zotero/storage/7V7DGQ6K/3.html:text/html},
}

@misc{istrate_large_2022,
	title = {A large dataset of software mentions in the biomedical literature},
	url = {http://arxiv.org/abs/2209.00693},
	doi = {10.48550/arXiv.2209.00693},
	abstract = {We describe the CZ Software Mentions dataset, a new dataset of software mentions in biomedical papers. Plain-text software mentions are extracted with a trained SciBERT model from several sources: the NIH PubMed Central collection and from papers provided by various publishers to the Chan Zuckerberg Initiative. The dataset provides sources, context and metadata, and, for a number of mentions, the disambiguated software entities and links. We extract 1.12 million unique string software mentions from 2.4 million papers in the NIH PMC-OA Commercial subset, 481k unique mentions from the NIH PMC-OA Non-Commercial subset (both gathered in October 2021) and 934k unique mentions from 3 million papers in the Publishers' collection. There is variation in how software is mentioned in papers and extracted by the NER algorithm. We propose a clustering-based disambiguation algorithm to map plain-text software mentions into distinct software entities and apply it on the NIH PubMed Central Commercial collection. Through this methodology, we disambiguate 1.12 million unique strings extracted by the NER model into 97600 unique software entities, covering 78\% of all software-paper links. We link 185000 of the mentions to a repository, covering about 55\% of all software-paper links. We describe in detail the process of building the datasets, disambiguating and linking the software mentions, as well as opportunities and challenges that come with a dataset of this size. We make all data and code publicly available as a new resource to help assess the impact of software (in particular scientific open source projects) on science.},
	urldate = {2022-09-30},
	publisher = {arXiv},
	author = {Istrate, Ana-Maria and Li, Donghui and Taraborelli, Dario and Torkar, Michaela and Veytsman, Boris and Williams, Ivana},
	month = sep,
	year = {2022},
	note = {arXiv:2209.00693 [cs, q-bio]},
	keywords = {Computer Science - Digital Libraries, Quantitative Biology - Other Quantitative Biology},
	file = {arXiv Fulltext PDF:/Users/carriewright/Zotero/storage/GV84NXBW/Istrate et al. - 2022 - A large dataset of software mentions in the biomed.pdf:application/pdf;arXiv.org Snapshot:/Users/carriewright/Zotero/storage/9EQ8JNKK/2209.html:text/html},
}

@article{schindler_role_2022,
	title = {The role of software in science: a knowledge graph-based analysis of software mentions in {PubMed} {Central}},
	volume = {8},
	issn = {2376-5992},
	shorttitle = {The role of software in science},
	url = {https://peerj.com/articles/cs-835},
	doi = {10.7717/peerj-cs.835},
	abstract = {Science across all disciplines has become increasingly data-driven, leading to additional needs with respect to software for collecting, processing and analysing data. Thus, transparency about software used as part of the scientific process is crucial to understand provenance of individual research data and insights, is a prerequisite for reproducibility and can enable macro-analysis of the evolution of scientific methods over time. However, missing rigor in software citation practices renders the automated detection and disambiguation of software mentions a challenging problem. In this work, we provide a large-scale analysis of software usage and citation practices facilitated through an unprecedented knowledge graph of software mentions and affiliated metadata generated through supervised information extraction models trained on a unique gold standard corpus and applied to more than 3 million scientific articles. Our information extraction approach distinguishes different types of software and mentions, disambiguates mentions and outperforms the state-of-the-art significantly, leading to the most comprehensive corpus of 11.8 M software mentions that are described through a knowledge graph consisting of more than 300 M triples. Our analysis provides insights into the evolution of software usage and citation patterns across various fields, ranks of journals, and impact of publications. Whereas, to the best of our knowledge, this is the most comprehensive analysis of software use and citation at the time, all data and models are shared publicly to facilitate further research into scientific use and citation of software.},
	language = {en},
	urldate = {2022-09-30},
	journal = {PeerJ Computer Science},
	author = {Schindler, David and Bensmann, Felix and Dietze, Stefan and Krüger, Frank},
	month = jan,
	year = {2022},
	note = {Publisher: PeerJ Inc.},
	pages = {e835},
	file = {Full Text PDF:/Users/carriewright/Zotero/storage/YK5LYD6H/Schindler et al. - 2022 - The role of software in science a knowledge graph.pdf:application/pdf;Snapshot:/Users/carriewright/Zotero/storage/4TLN6J8I/cs-835.html:text/html},
}

@article{du_softcite_2021,
	title = {Softcite dataset: {A} dataset of software mentions in biomedical and economic research publications},
	volume = {72},
	issn = {2330-1643},
	shorttitle = {Softcite dataset},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.24454},
	doi = {10.1002/asi.24454},
	abstract = {Software contributions to academic research are relatively invisible, especially to the formalized scholarly reputation system based on bibliometrics. In this article, we introduce a gold-standard dataset of software mentions from the manual annotation of 4,971 academic PDFs in biomedicine and economics. The dataset is intended to be used for automatic extraction of software mentions from PDF format research publications by supervised learning at scale. We provide a description of the dataset and an extended discussion of its creation process, including improved text conversion of academic PDFs. Finally, we reflect on our challenges and lessons learned during the dataset creation, in hope of encouraging more discussion about creating datasets for machine learning use.},
	language = {en},
	number = {7},
	urldate = {2022-09-30},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Du, Caifan and Cohoon, Johanna and Lopez, Patrice and Howison, James},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24454},
	pages = {870--884},
	file = {Snapshot:/Users/carriewright/Zotero/storage/DH6M6UZZ/asi.html:text/html},
}

@article{howison_software_2016,
	title = {Software in the scientific literature: {Problems} with seeing, finding, and using software mentioned in the biology literature},
	volume = {67},
	issn = {2330-1643},
	shorttitle = {Software in the scientific literature},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.23538},
	doi = {10.1002/asi.23538},
	abstract = {Software is increasingly crucial to scholarship, yet the visibility and usefulness of software in the scientific record are in question. Just as with data, the visibility of software in publications is related to incentives to share software in reusable ways, and so promote efficient science. In this article, we examine software in publications through content analysis of a random sample of 90 biology articles. We develop a coding scheme to identify software “mentions” and classify them according to their characteristics and ability to realize the functions of citations. Overall, we find diverse and problematic practices: Only between 31\% and 43\% of mentions involve formal citations; informal mentions are very common, even in high impact factor journals and across different kinds of software. Software is frequently inaccessible (15\%–29\% of packages in any form; between 90\% and 98\% of specific versions; only between 24\%–40\% provide source code). Cites to publications are particularly poor at providing version information, whereas informal mentions are particularly poor at providing crediting information. We provide recommendations to improve the practice of software citation, highlighting recent nascent efforts. Software plays an increasingly great role in scientific practice; it deserves a clear and useful place in scholarly communication.},
	language = {en},
	number = {9},
	urldate = {2022-09-30},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Howison, James and Bullard, Julia},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.23538},
	keywords = {bibliographic citations, biology, journals},
	pages = {2137--2155},
	file = {Snapshot:/Users/carriewright/Zotero/storage/NXFRF3TM/asi.html:text/html},
}

@misc{wade_cord-19_2021,
	title = {{CORD}-19 {Software} {Mentions}},
	copyright = {Creative Commons Zero v1.0 Universal},
	url = {http://datadryad.org/stash/dataset/doi:10.5061/dryad.vmcvdncs0},
	abstract = {In an effort to automate the process of identifying and analyzing the use of software in biomedical research, we have developed a SciBERT-based machine learning model to extract mentions of software from scientific articles. The input to this model is the full text from a scientific article and the output is a list of mentioned software within it. We applied this model to the CORD-19 full-text articles and stored the output in this dataset, which includes metadata of over 77,000 COVID-19 and coronavirus-related papers and a list of software tools mentioned in each.},
	language = {en},
	urldate = {2022-09-30},
	publisher = {Dryad},
	author = {Wade, Alex D. and Williams, Ivana},
	year = {2021},
	doi = {10.5061/DRYAD.VMCVDNCS0},
	note = {Artwork Size: 31878512 bytes
Pages: 31878512 bytes
Version Number: 6
Type: dataset},
	keywords = {FOS: Computer and information sciences, Research Software, Scholarly communication, scholarly impact, semi-supervised machine learning},
	annote = {Methods
We have developed a machine learning model to extract mentions of software from scientific articles. The SoftCite dataset was used to train and evaluate the model. This model has been applied to the CORD-19 collection of full-text coronavirus-related research papers. This dataset comprises the output of this model and each scientific article's relevant metadata. Data are derived from the CORD-19 dataset provided by AllenAI, release version 2021-02-08 (changelog cord-19\_2021-02-08.tar.gz 7.4GB c5446fea 29f69de2) downloaded from AWS on 08-Feb-2021.Other
Notes: Not all papers in the CORD-19 dataset mention software. We only include here the subset of articles for which there was full-text and which also had at least one detected software mention Software names have not been normalized, nor have they been resolved to any external dictionary. e.g. the list of software mentions includes “excel”, “microsoft excel”, “ms excel”, and “office excel”. Dataset contains DOIs for each mentioning paper where available (96\% of papers). External identifiers (such as PubMed Central IDs, PubMed PMIDs, and arXiv IDs) for the remainder of papers can often be imputed from the paper URLs, e.g. the arXiv ID for the paper with the URL "https://arxiv.org/pdf/2011.09270v1.pdf" is "2011.09270" In some cases, mentions of software are incorrectly separated into multiple tokens, e.g. ['scikit', 'learn'] Schema: Column Type Description paper\_id string ID of paper from CORD-19 dataset. 40-character sha1 of the PDF doi string Digital Object Identifier of the article, from CORD-19 title string Title of the article, from CORD-19 source\_x array Provenance of the article from CORD-19 dataset, e.g. arXiv, bioRxiv, Elsevier, Medline, PMC, WHO, Wiley license string License of the article, from CORD-19 publish\_time date (mm/dd/yyyy) Publication date of the article, from CORD-19 journal string Journal short name, from CORD-19 (e.g. PLoS Compu Biol) url array URL(s) of article, from CORD-19 software array Software mentions extracted from article full-text},
}

@book{gamma_design_1995,
	title = {Design {Patterns}: {Elements} of {Reusable} {Object}-{Oriented} {Software}},
	url = {https://www.pearson.com/en-us/subject-catalog/p/design-patterns-elements-of-reusable-object-oriented-software/P200000009480/9780201633610},
	urldate = {2022-10-05},
	publisher = {Addison-Wesley},
	author = {Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John},
	year = {1995},
	file = {Design Patterns\: Elements of Reusable Object-Oriented Software:/Users/carriewright/Zotero/storage/DV9N5J2V/9780201633610.html:text/html},
}

@book{cooper_inmates_2004,
	edition = {2nd},
	title = {Inmates {Are} {Running} the {Asylum}, {The}: {Why} {High}-{Tech} {Products} {Drive} {Us} {Crazy} and {How} to {Restore} the {Sanity} [{Book}]},
	isbn = {0-672-32614-0},
	shorttitle = {Inmates {Are} {Running} the {Asylum}, {The}},
	url = {https://www.oreilly.com/library/view/inmates-are-running/0672326140/},
	abstract = {Imagine, at a terrifyingly aggressive rate, everything you regularly use is being equipped with computer technology. Think about your phone, cameras, cars-everything-being automated and programmed by people who in their … - Selection from Inmates Are Running the Asylum, The: Why High-Tech Products Drive Us Crazy and How to Restore the Sanity [Book]},
	language = {en},
	urldate = {2022-10-05},
	publisher = {Sams},
	author = {Cooper, Alan},
	year = {2004},
	note = {ISBN: 9780672326141},
	file = {Snapshot:/Users/carriewright/Zotero/storage/B2IAIL6T/0672326140.html:text/html},
}

@techreport{chue_hong_software_2019,
	title = {Software {Citation} {Checklist} for {Developers}},
	url = {https://zenodo.org/record/3482769},
	abstract = {This document provides a minimal, generic checklist that developers of software (either open or closed source) used in research can use to ensure they are following good practice around software citation. This will help developers get credit for the software they create, and improve transparency, reproducibility, and reuse.},
	language = {eng},
	urldate = {2022-10-11},
	institution = {Zenodo},
	author = {Chue Hong, Neil P. and Allen, Alice and Gonzalez-Beltran and de Waard, Anita and Smith, Arfon M. and Robinson, Carly and Jones, Catherine and Bouquin, Daina and Katz, Daniel S. and Kennedy, David and Ryder, Gerry and Hausman, Jessica and Hwang, Lorraine and Jones, Matthew B. and Harrison, Melissa and Crosas, Mercè and Wu, Mingfang and Löwe, Peter and Haines, Robert and Edmunds, Scott and Stall, Shelley and Swaminathan, Sowmya and Druskat, Stephan and Crick, Tom and Morrell, Tom and Pollard, Tom},
	month = oct,
	year = {2019},
	doi = {10.5281/zenodo.3482769},
	keywords = {software citation},
	file = {Zenodo Snapshot:/Users/carriewright/Zotero/storage/FLUZJUH7/3482769.html:text/html},
}

@misc{peixoto_graph-tool_2017,
	title = {The graph-tool python library},
	url ={https://figshare.com/articles/dataset/graph_tool/1164194/14},
	urldate = {2022-10-11},
	author = {Peixoto, Tiago P.},
	year = {2017},
    }

@article{hoskin_awful_1996,
	title = {The "awful idea of accountability": inscribing people into the measurement of objects},
	shorttitle = {The "awful idea of accountability"},
	language = {eng},
	journal = {London: International Thomson Business Press.},
	author = {Hoskin, Keith},
	year = {1996},
	note = {Place: S.l.
Publisher: s.n.
OCLC: 848853299},
}

@article{fire_over-optimization_2019,
	title = {Over-optimization of academic publishing metrics: observing {Goodhart}’s {Law} in action},
	volume = {8},
	issn = {2047-217X},
	shorttitle = {Over-optimization of academic publishing metrics},
	url = {https://doi.org/10.1093/gigascience/giz053},
	doi = {10.1093/gigascience/giz053},
	abstract = {The academic publishing world is changing significantly, with ever-growing numbers of publications each year and shifting publishing patterns. However, the metrics used to measure academic success, such as the number of publications, citation number, and impact factor, have not changed for decades. Moreover, recent studies indicate that these metrics have become targets and follow Goodhart’s Law, according to which, “when a measure becomes a target, it ceases to be a good measure.”In this study, we analyzed \&gt;120 million papers to examine how the academic publishing world has evolved over the last century, with a deeper look into the specific field of biology. Our study shows that the validity of citation-based measures is being compromised and their usefulness is lessening. In particular, the number of publications has ceased to be a good metric as a result of longer author lists, shorter papers, and surging publication numbers. Citation-based metrics, such citation number and h-index, are likewise affected by the flood of papers, self-citations, and lengthy reference lists. Measures such as a journal’s impact factor have also ceased to be good metrics due to the soaring numbers of papers that are published in top journals, particularly from the same pool of authors. Moreover, by analyzing properties of \&gt;2,600 research fields, we observed that citation-based metrics are not beneficial for comparing researchers in different fields, or even in the same department.Academic publishing has changed considerably; now we need to reconsider how we measure success.},
	number = {6},
	urldate = {2022-10-11},
	journal = {GigaScience},
	author = {Fire, Michael and Guestrin, Carlos},
	month = jun,
	year = {2019},
	pages = {giz053},
	file = {Full Text PDF:/Users/carriewright/Zotero/storage/DVGSTGUY/Fire and Guestrin - 2019 - Over-optimization of academic publishing metrics .pdf:application/pdf;Snapshot:/Users/carriewright/Zotero/storage/Z58SV2B7/5506490.html:text/html},
}

@book{thomas_pragmatic_2019,
	title = {The {Pragmatic} {Programmer}, 20th {Anniversary} {Edition}},
	isbn = {978-0-13-595705-9},
	url = {https://pragprog.com/titles/tpp20/the-pragmatic-programmer-20th-anniversary-edition},
	abstract = {Andy and Dave wrote this seminal, classic book to help their clients create better software and rediscover the joy of coding. For over 20 years, the Pragmatic philosophy has spawned hundreds of our books, screencasts, audio books, and thousands of your careers and success stories.  \&lt;b\&gt;New!\&lt;/b\&gt; Revised 20th Anniversary Edition \&lt;a href=/titles/tpp20\&gt;is now available here\&lt;/a\&gt;. \&lt;b\&gt;Get it today and get on top of your game.\&lt;/b\&gt;},
	language = {en},
	urldate = {2022-10-12},
	publisher = {Addison-Wesley},
	author = {Thomas, David and Hunt, Andrew},
	year = {2019},
	note = {ISBN: 9780135957059},
	file = {Snapshot:/Users/carriewright/Zotero/storage/N2F4QNLE/the-pragmatic-programmer-20th-anniversary-edition.html:text/html},
}

@book{aurora_how_2019,
	edition = {1.1},
	title = {How to {Respond} to {Code} of {Conduct} {Reports}},
	isbn = {978-1-386-92257-5},
	url = {https://files.frameshiftconsulting.com/books/cocguide.pdf},
	publisher = {Frame Shift Consulting LLC https://frameshiftconsulting.com},
	author = {Aurora, Valerie and Gardiner, Mary},
	year = {2019},
}

@misc{noauthor_experiences_nodate,
	title = {Experiences and lessons learned from two virtual, hands-on microbiome bioinformatics workshops {\textbar} {PLOS} {Computational} {Biology}},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009056},
	urldate = {2022-10-12},
	file = {Experiences and lessons learned from two virtual, hands-on microbiome bioinformatics workshops | PLOS Computational Biology:/Users/carriewright/Zotero/storage/A6BBZEX8/article.html:text/html},
}

@article{dillon_experiences_2021,
	title = {Experiences and lessons learned from two virtual, hands-on microbiome bioinformatics workshops},
	volume = {17},
	issn = {1553-7358},
	doi = {10.1371/journal.pcbi.1009056},
	abstract = {In October of 2020, in response to the Coronavirus Disease 2019 (COVID-19) pandemic, our team hosted our first fully online workshop teaching the QIIME 2 microbiome bioinformatics platform. We had 75 enrolled participants who joined from at least 25 different countries on 6 continents, and we had 22 instructors on 4 continents. In the 5-day workshop, participants worked hands-on with a cloud-based shared compute cluster that we deployed for this course. The event was well received, and participants provided feedback and suggestions in a postworkshop questionnaire. In January of 2021, we followed this workshop with a second fully online workshop, incorporating lessons from the first. Here, we present details on the technology and protocols that we used to run these workshops, focusing on the first workshop and then introducing changes made for the second workshop. We discuss what worked well, what didn't work well, and what we plan to do differently in future workshops.},
	language = {eng},
	number = {6},
	journal = {PLoS computational biology},
	author = {Dillon, Matthew R. and Bolyen, Evan and Adamov, Anja and Belk, Aeriel and Borsom, Emily and Burcham, Zachary and Debelius, Justine W. and Deel, Heather and Emmons, Alex and Estaki, Mehrbod and Herman, Chloe and Keefe, Christopher R. and Morton, Jamie T. and Oliveira, Renato R. M. and Sanchez, Andrew and Simard, Anthony and Vázquez-Baeza, Yoshiki and Ziemski, Michal and Miwa, Hazuki E. and Kerere, Terry A. and Coote, Carline and Bonneau, Richard and Knight, Rob and Oliveira, Guilherme and Gopalasingam, Piraveen and Kaehler, Benjamin D. and Cope, Emily K. and Metcalf, Jessica L. and Robeson Ii, Michael S. and Bokulich, Nicholas A. and Caporaso, J. Gregory},
	month = jun,
	year = {2021},
	pmid = {34166363},
	pmcid = {PMC8224931},
	keywords = {Humans, Computational Biology, COVID-19, Feedback, Microbiota, SARS-CoV-2},
	pages = {e1009056},
	file = {Full Text:/Users/carriewright/Zotero/storage/LEMHEN56/Dillon et al. - 2021 - Experiences and lessons learned from two virtual, .pdf:application/pdf},
}

@inproceedings{meli_how_2019,
	address = {San Diego, CA},
	title = {How {Bad} {Can} {It} {Git}? {Characterizing} {Secret} {Leakage} in {Public} {GitHub} {Repositories}},
	isbn = {978-1-891562-55-6},
	shorttitle = {How {Bad} {Can} {It} {Git}?},
	url = {https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_04B-3_Meli_paper.pdf},
	doi = {10.14722/ndss.2019.23418},
	abstract = {GitHub and similar platforms have made public collaborative development of software commonplace. However, a problem arises when this public code must manage authentication secrets, such as API keys or cryptographic secrets. These secrets must be kept private for security, yet common development practices like adding these secrets to code make accidental leakage frequent. In this paper, we present the ﬁrst large-scale and longitudinal analysis of secret leakage on GitHub. We examine billions of ﬁles collected using two complementary approaches: a nearly six-month scan of real-time public GitHub commits and a public snapshot covering 13\% of open-source repositories. We focus on private key ﬁles and 11 high-impact platforms with distinctive API key formats. This focus allows us to develop conservative detection techniques that we manually and automatically evaluate to ensure accurate results. We ﬁnd that not only is secret leakage pervasive — affecting over 100,000 repositories — but that thousands of new, unique secrets are leaked every day. We also use our data to explore possible root causes of leakage and to evaluate potential mitigation strategies. This work shows that secret leakage on public repository platforms is rampant and far from a solved problem, placing developers and services at persistent risk of compromise and abuse.},
	language = {en},
	urldate = {2022-10-13},
	booktitle = {Proceedings 2019 {Network} and {Distributed} {System} {Security} {Symposium}},
	publisher = {Internet Society},
	author = {Meli, Michael and McNiece, Matthew R. and Reaves, Bradley},
	year = {2019},
	file = {Meli et al. - 2019 - How Bad Can It Git Characterizing Secret Leakage .pdf:/Users/carriewright/Zotero/storage/7KQJRAVR/Meli et al. - 2019 - How Bad Can It Git Characterizing Secret Leakage .pdf:application/pdf},
}

@misc{noauthor_static_nodate,
	title = {Static code analysis},
	url = {https://ieeexplore.ieee.org/document/1657940/},
	abstract = {Programmers usually employ static checkers, it checks our programs for errors without executing them, in a process called static code analysis. In this way, it works with a program that has an initial indication of correctness (because it compiles) and try to avoid well-known traps and pitfalls before measuring it against its specifications (when it's tested). We use FindBugs, a popular open source static code checker for Java. Static code checkers in Java come in two flavors: those that work directly on the program source code and those that work on the compiled bytecode. Although each code checker works in its own way, most share some basic traits. They read the program and construct some model of it, a kind of abstract representation that they can use for matching the error patterns they recognize. They also perform some kind of data-flow analysis, trying to infer the possible values that variables might have at certain points in the program. Data-flow analysis is especially important for vulnerability checking, an increasingly important area for code checkers},
	language = {en-US},
	urldate = {2022-10-13},
	file = {Snapshot:/Users/carriewright/Zotero/storage/G2EB5ZMC/1657940.html:text/html},
}

@misc{savonen_2021, 
 author = {Savonen, Candace}, 
 title = {Documentation and Usability}, 
 url = {https://bit.ly/docs-n-usability},
 year = {2021},
}

@inproceedings{ludwig_compiling_2017,
	title = {Compiling static software metrics for reliability and maintainability from {GitHub} repositories},
	doi = {10.1109/SMC.2017.8122569},
	abstract = {This paper identifies a small, essential set of static software code metrics linked to the software product quality characteristics of reliability and maintainability and to the most commonly identified sources of technical debt. A plug-in is created for the Understand code visualization and static analysis tool that calculates and aggregates the metrics. The plug-in produces a high-level interactive html report as well as developer-level information needed to address quality issues using Understand. A script makes use of Git, Understand, and the plug-in to compile results for a list of GitHub repositories into a single file. The primary contribution of this work is to describe an open-source plug-in to measure and visualize architectural complexity based on the propagation cost and core size metrics, which are not currently found in other tools. The plug-in should be useful to researchers and practitioners interested in these two metrics and as an expedient starting point to experimentation with metric collection and aggregation for groups of GitHub repositories. The plug-in was developed as a first step in an ongoing project aimed at applying case-based reasoning to the issue of software product quality.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Ludwig, Jeremy and Xu, Steven and Webber, Frederick},
	month = oct,
	year = {2017},
	keywords = {architecture, Complexity theory, maintainability, Measurement, metrics, reliability, software product quality, Software quality, Software reliability, static code analysis, technical debt, Tools},
	pages = {5--9},
	file = {IEEE Xplore Abstract Record:/Users/carriewright/Zotero/storage/TLVJR5GV/8122569.html:text/html},
}

@article{louridas_static_2006,
	title = {Static code analysis},
	volume = {23},
	issn = {1937-4194},
	doi = {10.1109/MS.2006.114},
	abstract = {Programmers usually employ static checkers, it checks our programs for errors without executing them, in a process called static code analysis. In this way, it works with a program that has an initial indication of correctness (because it compiles) and try to avoid well-known traps and pitfalls before measuring it against its specifications (when it's tested). We use FindBugs, a popular open source static code checker for Java. Static code checkers in Java come in two flavors: those that work directly on the program source code and those that work on the compiled bytecode. Although each code checker works in its own way, most share some basic traits. They read the program and construct some model of it, a kind of abstract representation that they can use for matching the error patterns they recognize. They also perform some kind of data-flow analysis, trying to infer the possible values that variables might have at certain points in the program. Data-flow analysis is especially important for vulnerability checking, an increasingly important area for code checkers},
	number = {4},
	journal = {IEEE Software},
	author = {Louridas, P.},
	month = jul,
	year = {2006},
	note = {Conference Name: IEEE Software},
	keywords = {Computer bugs, debugging, Insects, Inspection, Java, Open source software, software testing, Software testing, static checkers},
	pages = {58--61},
	file = {IEEE Xplore Abstract Record:/Users/carriewright/Zotero/storage/L34YA3S2/authors.html:text/html;IEEE Xplore Full Text PDF:/Users/carriewright/Zotero/storage/7S8QTUV7/Louridas - 2006 - Static code analysis.pdf:application/pdf},
}

@misc{noauthor_dependabot_nodate,
	title = {Dependabot},
	howpublished = {https://github.com/dependabot},
	urldate = {2022-10-13},
	journal = {GitHub},
	file = {Dependabot:/Users/carriewright/Zotero/storage/MAP9Q4ZQ/dependabot.html:text/html},
}

@inproceedings{alfadel_use_2021,
	title = {On the {Use} of {Dependabot} {Security} {Pull} {Requests}},
	doi = {10.1109/MSR52588.2021.00037},
	abstract = {Vulnerable dependencies are a major problem in modern software development. As software projects depend on multiple external dependencies, developers struggle to constantly track and check for corresponding security vulnerabilities that affect their project dependencies. To help mitigate this issue, Dependabot has been created, a bot that issues pull-requests to automatically update vulnerable dependencies. However, little is known about the degree to which developers adopt Dependabot to help them update vulnerable dependencies.In this paper, we investigate 2,904 JavaScript open-source GitHub projects that subscribed to Dependabot. Our results show that the vast majority (65.42\%) of the created security-related pull-requests are accepted, often merged within a day. Through manual analysis, we identify 7 main reasons for Dependabot security pull-requests not being merged, mostly related to concurrent modifications of the affected dependencies rather than Dependabot failures. Interestingly, only 3.2\% of the manually examined pull-requests suffered from build breakages. Finally, we model the time it takes to merge a Dependabot security pull-request using characteristics from projects, the fixed vulnerabilities and issued pull requests. Our model reveals 5 significant features to explain merge times, e.g., projects with relevant experience with Dependabot security pull-requests are most likely associated with rapid merges. Surprisingly, the severity of the dependency vulnerability and the potential risk of breaking changes are not strongly associated with the merge time. To the best of our knowledge, this study is the first to evaluate how developers receive Dependabot’s security contributions. Our findings indicate that Dependabot provides an effective platform for increasing awareness of dependency vulnerabilities and helps developers mitigate vulnerability threats in JavaScript projects.},
	booktitle = {2021 {IEEE}/{ACM} 18th {International} {Conference} on {Mining} {Software} {Repositories} ({MSR})},
	author = {Alfadel, Mahmoud and Costa, Diego Elias and Shihab, Emad and Mkhallalati, Mouafak},
	month = may,
	year = {2021},
	note = {ISSN: 2574-3864},
	keywords = {Open source software, Data mining, Dependabot, dependency, Manuals, pull request, Security, security vulnerability, Software development management},
	pages = {254--265},
	file = {IEEE Xplore Abstract Record:/Users/carriewright/Zotero/storage/NXHU3Y4E/9463148.html:text/html;IEEE Xplore Full Text PDF:/Users/carriewright/Zotero/storage/2LYZX3FU/Alfadel et al. - 2021 - On the Use of Dependabot Security Pull Requests.pdf:application/pdf},
}

@misc{merkel_docker_nodate,
	title = {Docker: {Lightweight} {Linux} {Containers} for {Consistent} {Development} and {Deployment}},
	url = {https://dl.acm.org/doi/fullHtml/10.5555/2600239.2600241},
	urldate = {2022-10-13},
	author = {Merkel, Dirk},
	file = {Docker\: Lightweight Linux Containers for Consistent Development and Deployment:/Users/carriewright/Zotero/storage/BUNYK4X8/2600239.html:text/html},
}

@article{combe_docker_2016,
	title = {To {Docker} or {Not} to {Docker}: {A} {Security} {Perspective}},
	volume = {3},
	issn = {2325-6095},
	shorttitle = {To {Docker} or {Not} to {Docker}},
	doi = {10.1109/MCC.2016.100},
	abstract = {The need for ever-shorter development cycles, continuous delivery, and cost savings in cloud-based infrastructures led to the rise of containers, which are more flexible than virtual machines and provide near-native performance. Among all container solutions, Docker, a complete packaging and software delivery tool, currently leads the market. This article gives an overview of the container ecosystem and discusses the Docker environment's security implications through realistic use cases. The authors define an adversary model, point out several vulnerabilities affecting current Docker usage, and discuss further research directions.},
	number = {5},
	journal = {IEEE Cloud Computing},
	author = {Combe, Theo and Martin, Antony and Di Pietro, Roberto},
	month = sep,
	year = {2016},
	note = {Conference Name: IEEE Cloud Computing},
	keywords = {cloud computing, Cloud computing, Computer security, containers, Containers, Cost benefit analysis, Docker, Linux, Product life cycle management, security, Virtual networks, virtualization},
	pages = {54--62},
	file = {IEEE Xplore Abstract Record:/Users/carriewright/Zotero/storage/VIFI3L4E/7742298.html:text/html;IEEE Xplore Full Text PDF:/Users/carriewright/Zotero/storage/DHXY3T63/Combe et al. - 2016 - To Docker or Not to Docker A Security Perspective.pdf:application/pdf},
}

@misc{bui_analysis_2015,
	title = {Analysis of {Docker} {Security}},
	url = {http://arxiv.org/abs/1501.02967},
	doi = {10.48550/arXiv.1501.02967},
	abstract = {Over the last few years, the use of virtualization technologies has increased dramatically. This makes the demand for efficient and secure virtualization solutions become more obvious. Container-based virtualization and hypervisor-based virtualization are two main types of virtualization technologies that have emerged to the market. Of these two classes, container-based virtualization is able to provide a more lightweight and efficient virtual environment, but not without security concerns. In this paper, we analyze the security level of Docker, a well-known representative of container-based approaches. The analysis considers two areas: (1) the internal security of Docker, and (2) how Docker interacts with the security features of the Linux kernel, such as SELinux and AppArmor, in order to harden the host system. Furthermore, the paper also discusses and identifies what could be done when using Docker to increase its level of security.},
	urldate = {2022-10-13},
	publisher = {arXiv},
	author = {Bui, Thanh},
	month = jan,
	year = {2015},
	note = {arXiv:1501.02967 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	file = {arXiv Fulltext PDF:/Users/carriewright/Zotero/storage/3ESRQQVN/Bui - 2015 - Analysis of Docker Security.pdf:application/pdf;arXiv.org Snapshot:/Users/carriewright/Zotero/storage/7MFVTUS9/1501.html:text/html},
}

@misc{noauthor_enabling_nodate,
	title = {Enabling {Docker} for {HPC} - {Sparks} - 2019 - {Concurrency} and {Computation}: {Practice} and {Experience} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/cpe.5018},
	urldate = {2022-10-13},
	file = {Enabling Docker for HPC - Sparks - 2019 - Concurrency and Computation\: Practice and Experience - Wiley Online Library:/Users/carriewright/Zotero/storage/Z9J2N4SB/cpe.html:text/html},
}

@inproceedings{bacis_dockerpolicymodules_2015,
	title = {{DockerPolicyModules}: {Mandatory} {Access} {Control} for {Docker} containers},
	shorttitle = {{DockerPolicyModules}},
	doi = {10.1109/CNS.2015.7346917},
	abstract = {The wide adoption of Docker and the ability to retrieve images from different sources impose strict security constraints. Docker leverages Linux kernel security facilities, such as namespaces, cgroups and Mandatory Access Control, to guarantee an effective isolation of containers. In order to increase Docker security and flexibility, we propose an extension to the Dockerfile format to let image maintainers ship a specific SELinux policy for the processes that run in a Docker image, enhancing the security of containers.},
	booktitle = {2015 {IEEE} {Conference} on {Communications} and {Network} {Security} ({CNS})},
	author = {Bacis, Enrico and Mutti, Simone and Capelli, Steven and Paraboschi, Stefano},
	month = sep,
	year = {2015},
	keywords = {Containers, Linux, Access control, Kernel, Proposals, Virtualization},
	pages = {749--750},
	file = {IEEE Xplore Abstract Record:/Users/carriewright/Zotero/storage/SBUI5E69/7346917.html:text/html;IEEE Xplore Full Text PDF:/Users/carriewright/Zotero/storage/PGY47CXZ/Bacis et al. - 2015 - DockerPolicyModules Mandatory Access Control for .pdf:application/pdf},
}

@article{sparks_enabling_2019,
	title = {Enabling {Docker} for {HPC}},
	volume = {31},
	issn = {1532-0634},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5018},
	doi = {10.1002/cpe.5018},
	abstract = {Docker is quickly becoming the de facto standard for containerization. Besides running on all the major Linux distributions, Docker is supported by each of the major cloud platform providers. The Docker ecosystem provides the capabilities necessary to build, manage, and execute containers on any platform. High-Performance Computer (HPC) systems present their own unique set of challenges to the standard deployment of Docker with respect to scale image storage, user security, and access to host-level resources. This paper presents a set of Docker API plugins and features to address the HPC concerns of scaling, security, resource access, and execution in an HPC Environment.},
	language = {en},
	number = {16},
	urldate = {2022-10-13},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Sparks, Jonathan},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.5018},
	keywords = {containers, Docker, security, HPC scaling},
	pages = {e5018},
	annote = {e5018 cpe.5018},
	file = {Full Text PDF:/Users/carriewright/Zotero/storage/VHMZMKQ9/Sparks - 2019 - Enabling Docker for HPC.pdf:application/pdf},
}

@misc{noauthor_singularity_nodate,
	title = {Singularity: {Scientific} containers for mobility of compute {\textbar} {PLOS} {ONE}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0177459},
	urldate = {2022-10-13},
	file = {Singularity\: Scientific containers for mobility of compute | PLOS ONE:/Users/carriewright/Zotero/storage/SQZBXAUQ/article.html:text/html},
}

@article{kurtzer_singularity_2017,
	title = {Singularity: {Scientific} containers for mobility of compute},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {Singularity},
	url = {https://dx.plos.org/10.1371/journal.pone.0177459},
	doi = {10.1371/journal.pone.0177459},
	abstract = {Here we present Singularity, software developed to bring containers and reproducibility to scientific computing. Using Singularity containers, developers can work in reproducible environments of their choosing and design, and these complete environments can easily be copied and executed on other platforms. Singularity is an open source initiative that harnesses the expertise of system and software engineers and researchers alike, and integrates seamlessly into common workflows for both of these groups. As its primary use case, Singularity brings mobility of computing to both users and HPC centers, providing a secure means to capture and distribute software and compute environments. This ability to create and deploy reproducible environments across these centers, a previously unmet need, makes Singularity a game changing development for computational science.},
	language = {en},
	number = {5},
	urldate = {2022-10-13},
	journal = {PLOS ONE},
	author = {Kurtzer, Gregory M. and Sochat, Vanessa and Bauer, Michael W.},
	editor = {Gursoy, Attila},
	month = may,
	year = {2017},
	pages = {e0177459},
	file = {Kurtzer et al. - 2017 - Singularity Scientific containers for mobility of.pdf:/Users/carriewright/Zotero/storage/75LGRVKV/Kurtzer et al. - 2017 - Singularity Scientific containers for mobility of.pdf:application/pdf},
}

@inproceedings{gantikow_rootless_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Rootless {Containers} with {Podman} for {HPC}},
	isbn = {978-3-030-59851-8},
	doi = {10.1007/978-3-030-59851-8_23},
	abstract = {Containers have become popular in HPC environments to improve the mobility of applications and the delivery of user-supplied code. In this paper we evaluate Podman, an enterprise container engine that supports rootless containers, in combination with runc and crun as container runtimes using a real-world workload with LS-DYNA, and the industry-standard benchmarks sysbench and STREAM. The results suggest that Podman with crun only introduces a similar low overhead as HPC-focused container technologies.},
	language = {en},
	booktitle = {High {Performance} {Computing}},
	publisher = {Springer International Publishing},
	author = {Gantikow, Holger and Walter, Steffen and Reich, Christoph},
	editor = {Jagode, Heike and Anzt, Hartwig and Juckeland, Guido and Ltaief, Hatem},
	year = {2020},
	keywords = {Virtualization, Benchmark, Container, crun, LS-DYNA, Performance analysis, Podman, Rootless containers, runc, Singularity},
	pages = {343--354},
	file = {Full Text PDF:/Users/carriewright/Zotero/storage/V7Q7SV5K/Gantikow et al. - 2020 - Rootless Containers with Podman for HPC.pdf:application/pdf},
}

@misc{yasrab_mitigating_2021,
	title = {Mitigating {Docker} {Security} {Issues}},
	url = {http://arxiv.org/abs/1804.05039},
	doi = {10.48550/arXiv.1804.05039},
	abstract = {Docker offers an ecosystem that offers a platform for application packaging, distributing, and managing within containers. However, the Docker platform has not yet matured. Presently, Docker is less secured than virtual machines (VM) and most of the other cloud technologies. The key to Dockers inadequate security protocols is container sharing of Linux kernel, which can lead to the risk of privileged escalations. This research will outline some significant security vulnerabilities at Docker and counter solutions to neutralize such attacks. There are a variety of security attacks like insider and outsider. This research will outline both types of attacks and their mitigations strategies. Taking some precautionary measures can save from massive disasters. This research will also present Docker secure deployment guidelines. These guidelines will suggest different configurations to deploy Docker containers in a more secure way.},
	urldate = {2022-10-13},
	publisher = {arXiv},
	author = {Yasrab, Robail},
	month = aug,
	year = {2021},
	note = {arXiv:1804.05039 [cs]},
	keywords = {Computer Science - Cryptography and Security, 91G20, 91B30, 91G40, 08A70, 11Y50, 65D17, 68-XX, 68N30, 68N18, B.2.3, B.3.4, Computer Science - Distributed, Parallel, and Cluster Computing, H.2.2, I.2.8, K.4.2, K.6.5, K.8.2},
	annote = {Comment: 13 pages},
	file = {arXiv Fulltext PDF:/Users/carriewright/Zotero/storage/LRY3ECZZ/Yasrab - 2021 - Mitigating Docker Security Issues.pdf:application/pdf;arXiv.org Snapshot:/Users/carriewright/Zotero/storage/CKD4YZS8/1804.html:text/html},
}



@misc{noauthor_altmetric_2015,
	title = {Altmetric badges},
	howpublished = {https://www.altmetric.com/products/altmetric-badges/},
	abstract = {Visit the post for more.},
	language = {en},
	urldate = {2022-10-13},
	journal = {Altmetric},
	month = jul,
	year = {2015},
	file = {Snapshot:/Users/carriewright/Zotero/storage/EENCHKPU/altmetric-badges.html:text/html},
}

@misc{noauthor_semantic_nodate,
	title = {Semantic {Scholar} {\textbar} {AI}-{Powered} {Research} {Tool}},
	howpublished = {https://www.semanticscholar.org/},
	urldate = {2022-10-13},
	file = {Semantic Scholar | AI-Powered Research Tool:/Users/carriewright/Zotero/storage/UMGS8VDX/www.semanticscholar.org.html:text/html},
}

@article{colavizza_citation_2020,
	title = {The citation advantage of linking publications to research data},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230416},
	doi = {10.1371/journal.pone.0230416},
	abstract = {Efforts to make research results open and reproducible are increasingly reflected by journal policies encouraging or mandating authors to provide data availability statements. As a consequence of this, there has been a strong uptake of data availability statements in recent literature. Nevertheless, it is still unclear what proportion of these statements actually contain well-formed links to data, for example via a URL or permanent identifier, and if there is an added value in providing such links. We consider 531, 889 journal articles published by PLOS and BMC, develop an automatic system for labelling their data availability statements according to four categories based on their content and the type of data availability they display, and finally analyze the citation advantage of different statement categories via regression. We find that, following mandated publisher policies, data availability statements become very common. In 2018 93.7\% of 21,793 PLOS articles and 88.2\% of 31,956 BMC articles had data availability statements. Data availability statements containing a link to data in a repository—rather than being available on request or included as supporting information files—are a fraction of the total. In 2017 and 2018, 20.8\% of PLOS publications and 12.2\% of BMC publications provided DAS containing a link to data in a repository. We also find an association between articles that include statements that link to data in a repository and up to 25.36\% (± 1.07\%) higher citation impact on average, using a citation prediction model. We discuss the potential implications of these results for authors (researchers) and journal publishers who make the effort of sharing their data in repositories. All our data and code are made available in order to reproduce and extend our results.},
	language = {en},
	number = {4},
	urldate = {2022-10-19},
	journal = {PLOS ONE},
	author = {Colavizza, Giovanni and Hrynaszkiewicz, Iain and Staden, Isla and Whitaker, Kirstie and McGillivray, Barbara},
	month = apr,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Bibliometrics, Scientific publishing, Science policy, Citation analysis, Data management, Open access publishing, Reproducibility, Support vector machines},
	pages = {e0230416},
	file = {Full Text PDF:/Users/carriewright/Zotero/storage/7HC4MNKE/Colavizza et al. - 2020 - The citation advantage of linking publications to .pdf:application/pdf;Snapshot:/Users/carriewright/Zotero/storage/HM8NAG6M/article.html:text/html},
}

@misc{gotterbarn_software_2006,
	title = {Software {Design} {Ethics} for {Biomedicine}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/0470032898.ch12},
	abstract = {Summary This chapter contains sections titled: The problem: software and research Risk identification Biomedical software example Is an ethical risk analysis required? Details of SoDIS A SoDIS anal...},
	language = {en},
	urldate = {2022-10-24},
	journal = {Wiley Online Library},
	author = {Gotterbarn, Don and Rogerson, Simon},
	month = may,
	year = {2006},
	note = {Pages: 211-231
Publisher: John Wiley \& Sons, Ltd},
	file = {Gotterbarn and Rogerson - 2006 - Software Design Ethics for Biomedicine.pdf:/Users/carriewright/Zotero/storage/PKRR9RUK/Gotterbarn and Rogerson - 2006 - Software Design Ethics for Biomedicine.pdf:application/pdf;Snapshot:/Users/carriewright/Zotero/storage/KYMPSGWG/showCitFormats.html:text/html},
}

@misc{google_analytics_privacy,
	title = {Privacy controls in {Google} {Analytics} {Analytics} {Help}},
	howpublished = {https://support.google.com/analytics/answer/9019185},
	urldate = {2023-02-07},
 }


@article{mantione_comparing_2014,
	title = {Comparing bioinformatic gene expression profiling methods: microarray and {RNA}-{Seq}},
	volume = {20},
	issn = {2325-4416},
	shorttitle = {Comparing bioinformatic gene expression profiling methods},
	doi = {10.12659/MSMBR.892101},
	abstract = {Understanding the control of gene expression is critical for our understanding of the relationship between genotype and phenotype. The need for reliable assessment of transcript abundance in biological samples has driven scientists to develop novel technologies such as DNA microarray and RNA-Seq to meet this demand. This review focuses on comparing the two most useful methods for whole transcriptome gene expression profiling. Microarrays are reliable and more cost effective than RNA-Seq for gene expression profiling in model organisms. RNA-Seq will eventually be used more routinely than microarray, but right now the techniques can be complementary to each other. Microarrays will not become obsolete but might be relegated to only a few uses. RNA-Seq clearly has a bright future in bioinformatic data collection.},
	language = {eng},
	journal = {Medical Science Monitor Basic Research},
	author = {Mantione, Kirk J. and Kream, Richard M. and Kuzelova, Hana and Ptacek, Radek and Raboch, Jiri and Samuel, Joshua M. and Stefano, George B.},
	month = aug,
	year = {2014},
	pmid = {25149683},
	pmcid = {PMC4152252},
	keywords = {Computational Biology, Gene Expression Profiling, Oligonucleotide Array Sequence Analysis, Sequence Analysis, RNA},
	pages = {138--142},
 }

 
@misc{mailchimp,
	title = {Marketing smarts for big ideas},
	howpublished = {https://mailchimp.com/},
	abstract = {Mailchimp helps small businesses do big things, with the right tools and guidance every step of the way.},
	language = {en},
	urldate = {2023-02-08},
	journal = {Mailchimp},
}


@misc{cronitor,
	title = {Cronitor},
	howpublished = {https://cronitor.io/},
	abstract = {Monitor and understand your critical cron jobs, background tasks, websites, APIs and more. Instant alerts when something goes wrong. Free 14 day trial.},
	language = {en},
	urldate = {2023-02-08},
	annote = {undefined},
}

@incollection{cron_2009,
	address = {Berkeley, CA},
    author = {Peters, Ron},
	title = {cron. In: Expert Shell Scripting. },
	isbn = {978-1-4302-1842-5},
	howpublished = {https://doi.org/10.1007/978-1-4302-1842-5_12},
	abstract = {The system scheduler on UNIX and Linux systems is called cron. Its purpose is to run commands, series of commands, or scripts on a predetermined schedule. Normally these tasks are performed on systems that run 24 hours a day, 7 days a week. Writing cron scripts to perform system maintenance, backups, monitors, or any other job that you would want to run on a schedule is a very common task. There are a few subtleties with cron however, that many users and administrators may be unaware of.},
	language = {en},
	urldate = {2023-02-08},
	booktitle = {Expert {Shell} {Scripting}},
	publisher = {Apress},
	editor = {Peters, Ron},
	year = {2009},
	doi = {10.1007/978-1-4302-1842-5_12},
	pages = {81--85},
	file = {Full Text PDF:/Users/carriewright/Zotero/storage/RC5AKK86/Peters - 2009 - cron.pdf:application/pdf},
}

@article{affy,
    title = {affy—analysis of Affymetrix GeneChip data at the probe level.},
    journal = {Bioinformatics},
    author = {Gautier L. and Cope L. and Bolstad B.M. and Irizarry R.A.},
    year = {2004},
    volume = {20},
    issue = {3},
    pages = {307–315},
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btg405}
}

@misc{hubspot,
	title = {Free {Email} {Tracking} {Software} {\textbar} {HubSpot}},
	howpublished = {https://www.hubspot.com/products/sales/email-tracking},
	language = {en-US, en},
	urldate = {2023-02-16},
	author = {HubSpot},
}

@article{xena_2020,
	title = {Visualizing and interpreting cancer genomics data via the {Xena} platform},
	volume = {38},
	copyright = {2020 Springer Nature America, Inc.},
	issn = {1546-1696},
	howpublished = {https://www.nature.com/articles/s41587-020-0546-8},
	doi = {10.1038/s41587-020-0546-8},
	language = {en},
	number = {6},
	urldate = {2023-02-16},
	journal = {Nature Biotechnology},
	author = {Goldman, Mary J. and Craft, Brian and Hastie, Mim and Repečka, Kristupas and McDade, Fran and Kamath, Akhil and Banerjee, Ayan and Luo, Yunhai and Rogers, Dave and Brooks, Angela N. and Zhu, Jingchun and Haussler, David},
	month = jun,
	year = {2020},
	note = {Number: 6
Publisher: Nature Publishing Group},
	keywords = {Cancer genomics, Software},
	pages = {675--678}
 }

 
@article{bitzer_intrinsic_2007,
	title = {Intrinsic motivation in open source software development},
	volume = {35},
	issn = {0147-5967},
	url = {https://www.sciencedirect.com/science/article/pii/S0147596706000643},
	doi = {10.1016/j.jce.2006.10.001},
	abstract = {This papers sheds light on the puzzling fact that even though open source software (OSS) is a public good, it is developed for free by highly qualified, young, motivated individuals, and evolves at a rapid pace. We show that when OSS development is understood as the private provision of a public good, these features emerge quite naturally. We adapt a dynamic private-provision-of-public-goods model to reflect key aspects of the OSS phenomenon, such as play value or homo ludens payoff, user-programmers' and gift culture benefits. Such intrinsic motives feature extensively in the wider OSS literature and contribute new insights to the economic analysis. Journal of Comparative Economics 35 (1) (2007) 160–169.},
	language = {en},
	number = {1},
	urldate = {2023-02-17},
	journal = {Journal of Comparative Economics},
	author = {Bitzer, Jürgen and Schrettl, Wolfram and Schröder, Philipp J. H.},
	month = mar,
	year = {2007},
	keywords = {Homo ludens, Open source software, Public goods, War of attrition},
	pages = {160--169},
}

@article{green_strategic_2020,
	title = {Strategic vision for improving human health at {The} {Forefront} of {Genomics}},
	volume = {586},
	issn = {0028-0836},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7869889/},
	doi = {10.1038/s41586-020-2817-4},
	abstract = {Starting with the launch of the Human Genome Project three decades ago, genomics has become progressively entrenched within the bedrock of the biomedical research enterprise. Capitalizing on the momentum of the project’s successful completion in 2003, genomics now regularly plays a central and catalytic role in basic and translational research, and studies increasingly demonstrate the vital role that genomic information can play in clinical care. Looking ahead, the anticipated advances in technology development, biological insights, and clinical applications (among others) will lead to more widespread integration of genomics into virtually all areas of biomedical research, the adoption of genomics into mainstream medical and public-health practices, and an increasing relevance of genomics in everyday life. On behalf of the research community, the National Human Genome Research Institute recently completed a multi-year process of strategic engagement to capture input about the future research priorities and opportunities in human genomics, with an emphasis on health applications. Here we articulate the highest-priority elements envisioned for the cutting-edge of human genomics going forward – that is, at “The Forefront of Genomics.”},
	number = {7831},
	urldate = {2023-02-17},
	journal = {Nature},
	author = {Green, Eric D. and Gunter, Chris and Biesecker, Leslie G. and Francesco, Valentina Di and Easter, Carla L. and Feingold, Elise A. and Felsenfeld, Adam L. and Kaufman, David J. and Ostrander, Elaine A. and Pavan, William J. and Phillippy, Adam M. and Wise, Anastasia L. and Dayal, Jyoti Gupta and Kish, Britny J. and Mandich, Allison and Wellington, Christopher R. and Wetterstrand, Kris A. and Bates, Sarah A. and Leja, Darryl and Vasquez, Susan and Gahl, William A. and Graham, Bettie J. and Kastner, Daniel L. and Liu, Paul and Rodriguez, Laura Lyman and Solomon, Benjamin D. and Bonham, Vence L. and Brody, Lawrence C. and Hutter, Carolyn M. and Manolio, Teri A.},
	month = oct,
	year = {2020},
	pmid = {33116284},
	pmcid = {PMC7869889},
	pages = {683--692},
}

@article{levet_developing_2021,
	title = {Developing open-source software for bioimage analysis: opportunities and challenges},
	volume = {10},
	issn = {2046-1402},
	shorttitle = {Developing open-source software for bioimage analysis},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8226416/},
	doi = {10.12688/f1000research.52531.1},
	abstract = {Fast-paced innovations in imaging have resulted in single systems producing exponential amounts of data to be analyzed. Computational methods developed in computer science labs have proven to be crucial for analyzing these data in an unbiased and efficient manner, reaching a prominent role in most microscopy studies. Still, their use usually requires expertise in bioimage analysis, and their accessibility for life scientists has therefore become a bottleneck.,  Open-source software for bioimage analysis has developed to disseminate these computational methods to a wider audience, and to life scientists in particular. In recent years, the influence of many open-source tools has grown tremendously, helping tens of thousands of life scientists in the process. As creators of successful open-source bioimage analysis software, we here discuss the motivations that can initiate development of a new tool, the common challenges faced, and the characteristics required for achieving success.},
	urldate = {2023-02-17},
	journal = {F1000Research},
	author = {Levet, Florian and Carpenter, Anne E. and Eliceiri, Kevin W. and Kreshuk, Anna and Bankhead, Peter and Haase, Robert},
	month = apr,
	year = {2021},
	pmid = {34249339},
	pmcid = {PMC8226416},
	pages = {302},
	file = {PubMed Central Full Text PDF:/Users/carriewright/Zotero/storage/X94D79WK/Levet et al. - 2021 - Developing open-source software for bioimage analy.pdf:application/pdf},
}

@article{itcr_open-source_2021,
	title = {Open-source {Software} {Sustainability} {Models}: {Initial} {White} {Paper} {From} the {Informatics} {Technology} for {Cancer} {Research} {Sustainability} and {Industry} {Partnership} {Working} {Group}},
	volume = {23},
	issn = {1439-4456},
	shorttitle = {Open-source {Software} {Sustainability} {Models}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8686402/},
	doi = {10.2196/20028},
	abstract = {Background
The National Cancer Institute Informatics Technology for Cancer Research (ITCR) program provides a series of funding mechanisms to create an ecosystem of open-source software (OSS) that serves the needs of cancer research. As the ITCR ecosystem substantially grows, it faces the challenge of the long-term sustainability of the software being developed by ITCR grantees. To address this challenge, the ITCR sustainability and industry partnership working group (SIP-WG) was convened in 2019.

Objective
The charter of the SIP-WG is to investigate options to enhance the long-term sustainability of the OSS being developed by ITCR, in part by developing a collection of business model archetypes that can serve as sustainability plans for ITCR OSS development initiatives. The working group assembled models from the ITCR program, from other studies, and from the engagement of its extensive network of relationships with other organizations (eg, Chan Zuckerberg Initiative, Open Source Initiative, and Software Sustainability Institute) in support of this objective.

Methods
This paper reviews the existing sustainability models and describes 10 OSS use cases disseminated by the SIP-WG and others, including 3D Slicer, Bioconductor, Cytoscape, Globus, i2b2 (Informatics for Integrating Biology and the Bedside) and tranSMART, Insight Toolkit, Linux, Observational Health Data Sciences and Informatics tools, R, and REDCap (Research Electronic Data Capture), in 10 sustainability aspects: governance, documentation, code quality, support, ecosystem collaboration, security, legal, finance, marketing, and dependency hygiene.

Results
Information available to the public reveals that all 10 OSS have effective governance, comprehensive documentation, high code quality, reliable dependency hygiene, strong user and developer support, and active marketing. These OSS include a variety of licensing models (eg, general public license version 2, general public license version 3, Berkeley Software Distribution, and Apache 3) and financial models (eg, federal research funding, industry and membership support, and commercial support). However, detailed information on ecosystem collaboration and security is not publicly provided by most OSS.

Conclusions
We recommend 6 essential attributes for research software: alignment with unmet scientific needs, a dedicated development team, a vibrant user community, a feasible licensing model, a sustainable financial model, and effective product management. We also stress important actions to be considered in future ITCR activities that involve the discussion of the sustainability and licensing models for ITCR OSS, the establishment of a central library, the allocation of consulting resources to code quality control, ecosystem collaboration, security, and dependency hygiene.},
	number = {12},
	urldate = {2023-02-17},
	journal = {Journal of Medical Internet Research},
	author = {Ye, Ye and Barapatre, Seemran and Davis, Michael K and Elliston, Keith O and Davatzikos, Christos and Fedorov, Andrey and Fillion-Robin, Jean-Christophe and Foster, Ian and Gilbertson, John R and Lasso, Andras and Miller, James V and Morgan, Martin and Pieper, Steve and Raumann, Brigitte E and Sarachan, Brion D and Savova, Guergana and Silverstein, Jonathan C and Taylor, Donald P and Zelnis, Joyce B and Zhang, Guo-Qiang and Cuticchia, Jamie and Becich, Michael J},
	month = dec,
	year = {2021},
	pmid = {34860667},
	pmcid = {PMC8686402},
	pages = {e20028},
}

@article{sansone_fairsharing_2019,
	title = {{FAIRsharing} as a community approach to standards, repositories and policies},
	volume = {37},
	copyright = {2019 The Author(s)},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-019-0080-8},
	doi = {10.1038/s41587-019-0080-8},
	language = {en},
	number = {4},
	urldate = {2023-01-13},
	journal = {Nature Biotechnology},
	author = {Sansone, Susanna-Assunta and McQuilton, Peter and Rocca-Serra, Philippe and Gonzalez-Beltran, Alejandra and Izzo, Massimiliano and Lister, Allyson L. and Thurston, Milo},
	month = apr,
	year = {2019},
	note = {Number: 4
Publisher: Nature Publishing Group},
	keywords = {Education, Research data, Research management, Data publication and archiving, Standards},
	pages = {358--367},
}

@misc{google_analytics,
	title = {Analytics {Tools} \& {Solutions} for {Your} {Business} - {Google} {Analytics}},
	howpublished = {https://marketingplatform.google.com/about/analytics/},
	abstract = {Google Analytics gives you the tools you need to better understand your customers. You can then use those business insights to take action, such as improving your website, creating tailored audience lists, and more.},
	language = {en},
	urldate = {2023-02-20},
	journal = {Google Marketing Platform},
}

@misc{sourceforge,
title = {sourceforge: The Complete Open-Source and Business Software Platform},
howpublished = {https://sourceforge.net/}
}

@misc{datadryad,
title = {Dryad},
howpublished = {https://datadryad.org/}
}

@misc{figshare,
	title = {figshare - credit for all your research},
	howpublished = {https://figshare.com/},
	urldate = {2023-02-20}
}

@misc{synapse,
	title = {Synapse | Sage Bionetworks},
	howpublished = {https://www.synapse.org/},
        abstract = {Organize your digital research assets. Get credit for your research. Collaborate with your colleagues and the public.},
	urldate = {2023-02-20}
}

@article{biostars,
    doi = {10.1371/journal.pcbi.1002216},
    author = {Parnell, Laurence D. AND Lindenbaum, Pierre AND Shameer, Khader AND Dall'Olio, Giovanni Marco AND Swan, Daniel C. AND Jensen, Lars Juhl AND Cockell, Simon J. AND Pedersen, Brent S. AND Mangan, Mary E. AND Miller, Christopher A. AND Albert, Istvan},
    journal = {PLOS Computational Biology},
    publisher = {Public Library of Science},
    title = {BioStar: An Online Question \& Answer Resource for the Bioinformatics Community},
    year = {2011},
    month = {10},
    volume = {7},
    url = {https://doi.org/10.1371/journal.pcbi.1002216},
    pages = {1-5},
    abstract = {null},
    number = {10},
}

@misc{bioinformaticsstackexchange,
	title = {Bioinformatics Stack Exchange},
	howpublished = {https://bioinformatics.stackexchange.com/},
	urldate = {2023-02-20}
}

@misc{discourse,
	title = {Discourse},
	howpublished = {https://www.discourse.org/},
	abstract = {Discourse is the 100\% open source discussion platform built for the next decade of the Internet.},
	language = {en},
	urldate = {2023-02-20},
	journal = {Discourse - Civilized Discussion},
}

@misc{bitbucket,
	title = {Bitbucket {\textbar} {Git} solution for teams using {Jira}},
	howpublished = {https://bitbucket.org/product},
	abstract = {Bitbucket Cloud is a Git-based code and CI/CD tool optimized for teams using Jira.},
	language = {en},
	urldate = {2023-02-20},
	journal = {Bitbucket},
	author = {Atlassian}
 }

 @misc{GitHub,
	title = {GitHub {\textbar} IT service management company
},
	howpublished = {https://github.org},
	language = {en},
	urldate = {2023-02-20},
	journal = {GitHub}
 }

 

   @misc{GitLab,
	title = {GitLab {\textbar} IT service management company
},
	howpublished = {https://about.gitlab.com/},
	language = {en},
	urldate = {2023-02-20},
	journal = {GitHub}
 }

 @misc{hootsuite,
	title = {Hootsuite - {The} {Best} {Way} {To} {Manage} {Social} {Media}},
	howpublished = {https://www.hootsuite.com/},
	abstract = {Hootsuite is a social media management platform for business. Manage all of your social media profiles including Twitter and Facebook from a single dashboard, schedule tweets and posts, and measure your results with Hootsuite Pro.},
	urldate = {2023-03-03}
}

@misc{creative_commons,
	title = {About {The} {Licenses} - {Creative} {Commons}},
	howpublished = {https://creativecommons.org/licenses/},
	abstract = {The Creative Commons copyright licenses and tools forge a balance inside the traditional “all rights reserved” setting that copyright law creates.},
	language = {en-US},
	urldate = {2023-03-03}
 }

   @Article{bioconductor,
    author = {W. Huber and V. J. Carey and R. Gentleman and S. Anders and M. Carlson and B. S. Carvalho and H. C. Bravo and S. Davis and L. Gatto and T. Girke and R. Gottardo and F. Hahne and K. D. Hansen and R. A. Irizarry and M. Lawrence and M. I. Love and J. MacDonald and V. Obenchain and A. K. {Ole's} and H. {Pag`es} and A. Reyes and P. Shannon and G. K. Smyth and D. Tenenbaum and L. Waldron and M. Morgan},
    title = {{O}rchestrating high-throughput genomic analysis with {B}ioconductor},
    journal = {Nature Methods},
    year = {2015},
    volume = {12},
    number = {2},
    pages = {115--121},
    howpublished = {http://www.nature.com/nmeth/journal/v12/n2/full/nmeth.3252.html},
  }

  @article{reich_genepattern_2017,
	title = {The {GenePattern} {Notebook} {Environment}},
	volume = {5},
	issn = {2405-4712},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5572818/},
	doi = {10.1016/j.cels.2017.07.003},
	abstract = {Interactive analysis notebook environments promise to streamline genomics research through interleaving text, multimedia, and executable code into unified, sharable, reproducible “research narratives.” However, current notebook systems require programming knowledge, limiting their wider adoption by the research community. We have developed the GenePattern Notebook environment, www.genepattern-notebook.org, to our knowledge the first system to integrate the dynamic capabilities of notebook systems with an investigator-focused, easy-to-use interface that provides access to hundreds of genomic tools without the need to write code., Reich et. al have developed software that integrates the capabilities of electronic analysis notebooks and bioinformatics analysis portals. GenePattern Notebook uses the popular Jupyter Notebook platform that interleaves text, graphics, and code, and brings these tools for reproducible research, as well as access to hundreds of bioinformatics analyses, to non-programmers.,},
	number = {2},
	urldate = {2023-03-03},
	journal = {Cell systems},
	author = {Reich, Michael and Tabor, Thorin and Liefeld, Ted and Thorvaldsdóttir, Helga and Hill, Barbara and Tamayo, Pablo and Mesirov, Jill P.},
	month = aug,
	year = {2017},
	pmid = {28822753},
	pmcid = {PMC5572818},
	pages = {149--151.e1},
}

@article{the_galaxy_community_galaxy_2022,
	title = {The {Galaxy} platform for accessible, reproducible and collaborative biomedical analyses: 2022 update},
	volume = {50},
	issn = {0305-1048},
	shorttitle = {The {Galaxy} platform for accessible, reproducible and collaborative biomedical analyses},
	url = {https://doi.org/10.1093/nar/gkac247},
	doi = {10.1093/nar/gkac247},
	abstract = {Galaxy is a mature, browser accessible workbench for scientific computing. It enables scientists to share, analyze and visualize their own data, with minimal technical impediments. A thriving global community continues to use, maintain and contribute to the project, with support from multiple national infrastructure providers that enable freely accessible analysis and training services. The Galaxy Training Network supports free, self-directed, virtual training with \&gt;230 integrated tutorials. Project engagement metrics have continued to grow over the last 2 years, including source code contributions, publications, software packages wrapped as tools, registered users and their daily analysis jobs, and new independent specialized servers. Key Galaxy technical developments include an improved user interface for launching large-scale analyses with many files, interactive tools for exploratory data analysis, and a complete suite of machine learning tools. Important scientific developments enabled by Galaxy include Vertebrate Genome Project (VGP) assembly workflows and global SARS-CoV-2 collaborations.},
	number = {W1},
	urldate = {2023-03-03},
	journal = {Nucleic Acids Research},
	author = {{The Galaxy Community}},
	month = jul,
	year = {2022},
	pages = {W345--W351},
 }

 @article{hanauer_supporting_2015,
	title = {Supporting information retrieval from electronic health records: {A} report of {University} of {Michigan}'s nine-year experience in developing and using the {Electronic} {Medical} {Record} {Search} {Engine} ({EMERSE})},
	volume = {55},
	issn = {1532-0480},
	shorttitle = {Supporting information retrieval from electronic health records},
	doi = {10.1016/j.jbi.2015.05.003},
	abstract = {OBJECTIVE: This paper describes the University of Michigan's nine-year experience in developing and using a full-text search engine designed to facilitate information retrieval (IR) from narrative documents stored in electronic health records (EHRs). The system, called the Electronic Medical Record Search Engine (EMERSE), functions similar to Google but is equipped with special functionalities for handling challenges unique to retrieving information from medical text.
MATERIALS AND METHODS: Key features that distinguish EMERSE from general-purpose search engines are discussed, with an emphasis on functions crucial to (1) improving medical IR performance and (2) assuring search quality and results consistency regardless of users' medical background, stage of training, or level of technical expertise.
RESULTS: Since its initial deployment, EMERSE has been enthusiastically embraced by clinicians, administrators, and clinical and translational researchers. To date, the system has been used in supporting more than 750 research projects yielding 80 peer-reviewed publications. In several evaluation studies, EMERSE demonstrated very high levels of sensitivity and specificity in addition to greatly improved chart review efficiency.
DISCUSSION: Increased availability of electronic data in healthcare does not automatically warrant increased availability of information. The success of EMERSE at our institution illustrates that free-text EHR search engines can be a valuable tool to help practitioners and researchers retrieve information from EHRs more effectively and efficiently, enabling critical tasks such as patient case synthesis and research data abstraction.
CONCLUSION: EMERSE, available free of charge for academic use, represents a state-of-the-art medical IR tool with proven effectiveness and user acceptance.},
	language = {eng},
	journal = {Journal of Biomedical Informatics},
	author = {Hanauer, David A. and Mei, Qiaozhu and Law, James and Khanna, Ritu and Zheng, Kai},
	month = jun,
	year = {2015},
	pmid = {25979153},
	pmcid = {PMC4527540},
	keywords = {Data Mining, Electronic Health Records, Electronic health records (E05.318.308.940.968.625.500), Information storage and retrieval (L01.470), Meaningful Use, Michigan, Natural Language Processing, Search Engine, Search engine (L01.470.875), Software, Software Validation},
	pages = {290--300},
}

@article{kent_human_2002,
	title = {The human genome browser at {UCSC}},
	volume = {12},
	issn = {1088-9051},
	doi = {10.1101/gr.229102},
	abstract = {As vertebrate genome sequences near completion and research refocuses to their analysis, the issue of effective genome annotation display becomes critical. A mature web tool for rapid and reliable display of any requested portion of the genome at any scale, together with several dozen aligned annotation tracks, is provided at http://genome.ucsc.edu. This browser displays assembly contigs and gaps, mRNA and expressed sequence tag alignments, multiple gene predictions, cross-species homologies, single nucleotide polymorphisms, sequence-tagged sites, radiation hybrid data, transposon repeats, and more as a stack of coregistered tracks. Text and sequence-based searches provide quick and precise access to any region of specific interest. Secondary links from individual features lead to sequence details and supplementary off-site databases. One-half of the annotation tracks are computed at the University of California, Santa Cruz from publicly available sequence data; collaborators worldwide provide the rest. Users can stably add their own custom tracks to the browser for educational or research purposes. The conceptual and technical framework of the browser, its underlying MYSQL database, and overall use are described. The web site currently serves over 50,000 pages per day to over 3000 different users.},
	language = {eng},
	number = {6},
	journal = {Genome Research},
	author = {Kent, W. James and Sugnet, Charles W. and Furey, Terrence S. and Roskin, Krishna M. and Pringle, Tom H. and Zahler, Alan M. and Haussler, David},
	month = jun,
	year = {2002},
	pmid = {12045153},
	pmcid = {PMC186604},
	keywords = {California, Database Management Systems, Databases, Genetic, Gene Expression, Genes, Genome, Human, Humans, RNA, Messenger, Sequence Homology, Nucleic Acid, Software, Universities},
	pages = {996--1006},
}

@misc{ucsc,
	title = {{UCSC} {Genome} {Browser} {Home}},
	howpublished = {https://genome.ucsc.edu/index.html},
	urldate = {2023-03-03},
}

@misc{github_actions,
	title = {Understanding {GitHub} {Actions}},
	url = {https://ghdocs-prod.azurewebsites.net/en/actions/learn-github-actions/understanding-github-actions},
	abstract = {Learn the basics of GitHub Actions, including core concepts and essential terminology.},
	language = {en},
	urldate = {2023-03-03},
	journal = {GitHub Docs},
}

@article{merow_better_2023,
	title = {Better incentives are needed to reward academic software development},
	copyright = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2397-334X},
	url = {https://www.nature.com/articles/s41559-023-02008-w},
	doi = {10.1038/s41559-023-02008-w},
	language = {en},
	urldate = {2023-03-08},
	journal = {Nature Ecology \& Evolution},
	author = {Merow, Cory and Boyle, Brad and Enquist, Brian J. and Feng, Xiao and Kass, Jamie M. and Maitner, Brian S. and McGill, Brian and Owens, Hannah and Park, Daniel S. and Paz, Andrea and Pinilla-Buitrago, Gonzalo E. and Urban, Mark C. and Varela, Sara and Wilson, Adam M.},
	month = feb,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biological techniques, Computational biology and bioinformatics, Ecology, Evolution},
	pages = {1--2}
 }

 @article{aksoy_ctd2_2017,
	title = {{CTD2} {Dashboard}: a searchable web interface to connect validated results from the {Cancer} {Target} {Discovery} and {Development} {Network}},
	volume = {2017},
	issn = {1758-0463},
	shorttitle = {{CTD2} {Dashboard}},
	url = {https://doi.org/10.1093/database/bax054},
	doi = {10.1093/database/bax054},
	abstract = {The Cancer Target Discovery and Development (CTD2) Network aims to use functional genomics to accelerate the translation of high-throughput and high-content genomic and small-molecule data towards use in precision oncology. As part of this goal, and to share its conclusions with the research community, the Network developed the ‘CTD2 Dashboard’ [https://ctd2-dashboard.nci.nih.gov/], which compiles CTD2 Network-generated conclusions, termed ‘observations’, associated with experimental entities, collected by its member groups (‘Centers’). Any researcher interested in learning about a given gene, protein, or compound (a ‘subject’) studied by the Network can come to the CTD2 Dashboard to quickly and easily find, review, and understand Network-generated experimental results. In particular, the Dashboard allows visitors to connect experiments about the same target, biomarker, etc., carried out by multiple Centers in the Network. The Dashboard’s unique knowledge representation allows information to be compiled around a subject, so as to become greater than the sum of the individual contributions. The CTD2 Network has broadly defined levels of validation for evidence (‘Tiers’) pertaining to a particular finding, and the CTD2 Dashboard uses these Tiers to indicate the extent to which results have been validated. Researchers can use the Network’s insights and tools to develop a new hypothesis or confirm existing hypotheses, in turn advancing the findings towards clinical applications.Database URL:https://ctd2-dashboard.nci.nih.gov/},
	urldate = {2023-03-28},
	journal = {Database},
	author = {Aksoy, Bülent Arman and Dančík, Vlado and Smith, Kenneth and Mazerik, Jessica N. and Ji, Zhou and Gross, Benjamin and Nikolova, Olga and Jaber, Nadia and Califano, Andrea and Schreiber, Stuart L. and Gerhard, Daniela S. and Hermida, Leandro C. and Jagu, Subhashini and Sander, Chris and Floratos, Aris and Clemons, Paul A.},
	month = jan,
	year = {2017},
	pages = {bax054}
}

@article{kibbe_cancer_2017,
	title = {Cancer {Informatics}: {New} {Tools} for a {Data}-{Driven} {Age} in {Cancer} {Research}},
	volume = {77},
	issn = {0008-5472},
	shorttitle = {Cancer {Informatics}},
	url = {https://doi.org/10.1158/0008-5472.CAN-17-2212},
	doi = {10.1158/0008-5472.CAN-17-2212},
	number = {21},
	urldate = {2023-03-28},
	journal = {Cancer Research},
	author = {Kibbe, Warren and Klemm, Juli and Quackenbush, John},
	month = oct,
	year = {2017},
	pages = {e1--e2}
 }

 @article{warner_informatics_2020,
	title = {Informatics {Tools} for {Cancer} {Research} and {Care}: {Bridging} the {Gap} {Between} {Innovation} and {Implementation}},
	shorttitle = {Informatics {Tools} for {Cancer} {Research} and {Care}},
	url = {https://ascopubs.org/doi/full/10.1200/CCI.20.00086},
	doi = {10.1200/CCI.20.00086},
        volume = {4},
	urldate = {2023-03-28},
	journal = {JCO Clinical Cancer Informatics},
	author = {Warner, Jeremy L. and Klemm, Juli D.},
	month = nov,
	year = {2020},
	note = {Publisher: Wolters Kluwer},
	pages = {784--786},
 }

 @misc{CZ_essential_2019,
	title = {Essential {Open} {Source} {Software} for {Science}},
	url = {https://cziscience.medium.com/essential-open-source-software-for-science-72faec2c38c1},
	abstract = {Supporting the Computational Foundations of Biology},
	language = {en},
	urldate = {2023-03-28},
	journal = {Medium},
	author = {Chan Zuckerberg Initiative Science},
	month = nov,
	year = {2019},
}

@Manual{S4Vectors,
    title = {S4Vectors: Foundation of vector-like and list-like containers in
Bioconductor},
    author = {H. Pagès and M. Lawrence and P. Aboyoun},
    year = {2022},
    note = {R package version 0.34.0},
    howpublished = {https://bioconductor.org/packages/S4Vectors},
  }


@inproceedings{meli2019bad,
  title={How bad can it git? characterizing secret leakage in public github repositories.},
  author={Meli, Michael and McNiece, Matthew R and Reaves, Bradley},
  booktitle={NDSS},
  year={2019},
  doi={10.14722/ndss.2019.23418}
}

@article{louridas2006static,
  title={Static code analysis},
  author={Louridas, Panagiotis},
  journal={Ieee Software},
  volume={23},
  number={4},
  pages={58--61},
  year={2006},
  publisher={IEEE},
  doi={10.1109/MS.2006.114}
}

@inproceedings{ludwig2017compiling,
  title={Compiling static software metrics for reliability and maintainability from GitHub repositories},
  author={Ludwig, Jeremy and Xu, Steven and Webber, Frederick},
  booktitle={2017 IEEE international conference on systems, man, and cybernetics (SMC)},
  pages={5--9},
  year={2017},
  organization={IEEE},
  doi={10.1109/SMC.2017.8122569}
}

@inproceedings{alfadel2021use,
  title={On the use of dependabot security pull requests},
  author={Alfadel, Mahmoud and Costa, Diego Elias and Shihab, Emad and Mkhallalati, Mouafak},
  booktitle={2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)},
  pages={254--265},
  year={2021},
  organization={IEEE},
  doi={10.1109/MSR52588.2021.00037}
}

@article{merkel2014docker,
  title={Docker: lightweight linux containers for consistent development and deployment},
  author={Merkel, Dirk and others},
  journal={Linux j},
  volume={239},
  number={2},
  pages={2},
  year={2014},
  doi={10.5555/2600239.2600241}
}

@article{combe2016docker,
  title={To docker or not to docker: A security perspective},
  author={Combe, Theo and Martin, Antony and Di Pietro, Roberto},
  journal={IEEE Cloud Computing},
  volume={3},
  number={5},
  pages={54--62},
  year={2016},
  publisher={IEEE},
  doi={10.1109/MCC.2016.100}
}

@article{bui2015analysis,
  title={Analysis of docker security},
  author={Bui, Thanh},
  journal={arXiv preprint arXiv:1501.02967},
  year={2015},
  doi={10.48550/arXiv.1501.02967}
}

@article{sparks2019enabling,
  title={Enabling docker for HPC},
  author={Sparks, Jonathan},
  journal={Concurrency and Computation: Practice and Experience},
  volume={31},
  number={16},
  pages={e5018},
  year={2019},
  publisher={Wiley Online Library},
  doi={10.1002/cpe.5018}
}

@inproceedings{bacis2015dockerpolicymodules,
  title={DockerPolicyModules: mandatory access control for docker containers},
  author={Bacis, Enrico and Mutti, Simone and Capelli, Steven and Paraboschi, Stefano},
  booktitle={2015 IEEE Conference on Communications and Network Security (CNS)},
  pages={749--750},
  year={2015},
  organization={IEEE},
  doi={10.1109/CNS.2015.7346917}
}

@article{kurtzer2017singularity,
  title={Singularity: Scientific containers for mobility of compute},
  author={Kurtzer, Gregory M and Sochat, Vanessa and Bauer, Michael W},
  journal={PloS one},
  volume={12},
  number={5},
  pages={e0177459},
  year={2017},
  publisher={Public Library of Science San Francisco, CA USA},
  doi={10.1371/journal.pone.0177459}
}

@inproceedings{gantikow2020rootless,
  title={Rootless containers with Podman for HPC},
  author={Gantikow, Holger and Walter, Steffen and Reich, Christoph},
  booktitle={High Performance Computing: ISC High Performance 2020 International Workshops, Frankfurt, Germany, June 21--25, 2020, Revised Selected Papers},
  pages={343--354},
  year={2020},
  organization={Springer},
  doi={10.1007/978-3-030-59851-8_23}
}

@article{yasrab2018mitigating,
  title={Mitigating docker security issues},
  author={Yasrab, Robail},
  journal={arXiv preprint arXiv:1804.05039},
  year={2018},
  doi={10.48550/arXiv.1804.05039}
}